## Background

Users can apply popular AI techniques that I have built here from scratch.

I entered the neural network code into a Kaggle competition to recognize digits in the MNIST dataset.

From the Kaggle competition [page](https://www.kaggle.com/c/digit-recognizer):
> MNIST ("Modified National Institute of Standards and Technology") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.

My neural network achieved a score of 0.95780 when run on Kaggle's test data.

## Decision Trees

Users can classify the emails in an very large email dataset as "ham" (legitimate) or spam by running a single decision tree, or a random forest.

## K-Nearest Neighbors

For multiple groups of __n__ points with a certain class __c__, I assigned the class whose points were closest on average to my point __p__.

The dataset that I used this algorithm on is also MNIST.

## Neural Network

Recognize digits from the MNIST dataset using a neural network.
